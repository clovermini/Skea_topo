import math
import torch
import cv2
import numpy as np
from skimage import metrics
from skimage import morphology, measure
from skimage.measure import label
from sklearn.metrics.cluster import rand_score, adjusted_rand_score
import gala.evaluate as ev
from typing import Tuple
import matplotlib.pyplot as plt


def miou(pred: np.ndarray, mask: np.ndarray, n_cl=2) -> float:
    """
    :param pred: prediction
    :param mask: ground truth
    :param n_cl: class number
    :return: miou_score
    """
    if np.amax(mask) == 255 and n_cl == 2:
        pred = pred / 255
        mask = mask / 255
    iou = 0
    for i_cl in range(0, n_cl):
        intersection = np.count_nonzero(mask[pred == i_cl] == i_cl)
        union = np.count_nonzero(mask == i_cl) + np.count_nonzero(pred == i_cl) - intersection
        iou += intersection / union
    miou_score = iou / n_cl
    return miou_score


def mdice(pred: np.ndarray, mask: np.ndarray, n_cl=2) -> float:
    """
    :param pred: prediction
    :param mask: ground truth
    :param n_cl: class number
    :return: mdice_score
    """
    if np.amax(mask) == 255 and n_cl == 2:
        pred = pred / 255
        mask = mask / 255
    dice = 0
    for i_cl in range(0, n_cl):
        intersection = np.count_nonzero(mask[pred == i_cl] == i_cl)
        area_sum = np.count_nonzero(mask == i_cl) + np.count_nonzero(pred == i_cl)
        dice += 2 * intersection / area_sum
    mdice_score = dice / n_cl
    return mdice_score


def filter_small_holes_func(mask_label, label_num, is_fore=True):
    left_num = 0
    filter_num = 20  # Background, small holes.
    if is_fore:   # Foreground, small line segments.
        filter_num = 30
    for i in range(1, label_num+1):
        if np.sum(mask_label == i) > filter_num:
            left_num += 1
    return left_num


def get_betti_own(x, is_show=False, filter_small_holes=False):  # binary_image  foreground 1ï¼Œ background 0
    # The 0th Betti number ð‘0 represents the number of connected components, is equivalent to counting the number of connected components in the foreground.
    # The 1st Betti number ð‘1 represents the number of holes, is equivalent to counting the number of connected components in the background.
    # the 2nd Betti number ð‘2 represents the number of cavities. 
    mask_label_0, label_num_0 = measure.label(x, connectivity=2, background=0, return_num=True) # label foreground connected regions
    mask_label_1, label_num_1 = measure.label(x, connectivity=1, background=1, return_num=True) # label background connected regions
    if is_show:   # show case
        plt.figure(figsize=(15, 5))
        plt.subplot(1,3,1), plt.imshow(x, cmap='plasma'), plt.axis("off")
        plt.subplot(1,3,2), plt.imshow(mask_label_0, cmap='plasma'), plt.axis("off")
        plt.subplot(1,3,3), plt.imshow(mask_label_1, cmap='plasma'),  plt.axis("off")
        plt.show()
    
    if filter_small_holes:
        label_num_0_filter = filter_small_holes_func(mask_label_0, label_num_0, is_fore=True)
        label_num_1_filter = filter_small_holes_func(mask_label_1, label_num_1, is_fore=False)
        return label_num_0_filter, label_num_1_filter
    return label_num_0, label_num_1


def compute_bettis_own(pred, label, filter_small_holes=False):
    label_betti0, label_betti1 = get_betti_own(label)
    pred_betti0, pred_betti1 = get_betti_own(pred, filter_small_holes=filter_small_holes)

    betti0_error = abs(label_betti0-pred_betti0)
    betti1_error = abs(label_betti1-pred_betti1)
    return betti0_error+betti1_error, betti0_error, betti1_error


def map_2018kdsb(pred: np.ndarray, mask: np.ndarray, bg_value = 1) -> float:
    """
    he metric is referenced from 2018 kaggle data science bowl: 
    https://www.kaggle.com/c/data-science-bowl-2018/overview/evaluation
    :param pred: prediction
    :param mask: ground truth
    :param bg_value: background value used for label function
    :return: map_score
    """
    thresholds = np.array([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])
    tp = np.zeros(10)
    fp = np.zeros(10)
    fn = np.zeros(10)
    if np.amax(mask) == 255:
        pred = pred / 255
        mask = mask / 255
    # optimize border of image
    pred[0, :] = bg_value; pred[:, 0] = bg_value; pred[-1, :] = bg_value; pred[:, -1] = bg_value
    mask[0, :] = bg_value; mask[:, 0] = bg_value; mask[-1, :] = bg_value; mask[:, -1] = bg_value
        
    label_mask, num_mask = label(mask, connectivity=1, background=bg_value, return_num=True)
    label_pred, num_pred = label(pred, connectivity=1, background=bg_value, return_num=True)
    
    for i_pred in range(1, num_pred + 1):
        intersect_mask_labels = list(np.unique(label_mask[label_pred == i_pred]))   # Get all labels intersecting with it
        # å¯¹ä¸Žå…¶ç›¸äº¤çš„çš„æ‰€æœ‰mask labelè®¡ç®—iouï¼ŒåŽå–å…¶æœ€å€¼  Calculate IOU for all mask labels intersecting with it, then take the maximum value
        if 0 in intersect_mask_labels:
            intersect_mask_labels.remove(0)

        if len(intersect_mask_labels) == 0:   # å¦‚æžœpredçš„æŸä¸€ä¸ªlabelæ²¡æœ‰ä¸Žä¹‹å¯¹åº”çš„maskçš„label,åˆ™ç»§ç»­ä¸‹ä¸€ä¸ªlabel  If a label in 'pred' does not have a corresponding label in the mask, then move on to the next label.
            continue
        
        intersect_mask_label_area = np.zeros((len(intersect_mask_labels), 1))
        union_mask_label_area = np.zeros((len(intersect_mask_labels), 1))
        
        for index, i_mask in enumerate(intersect_mask_labels):
            intersect_mask_label_area[index, 0] = np.count_nonzero(label_pred[label_mask == i_mask] == i_pred)
            union_mask_label_area[index, 0] = np.count_nonzero((label_mask == i_mask) | (label_pred == i_pred))
        iou = intersect_mask_label_area / union_mask_label_area
        max_iou = np.max(iou, axis=0)
        # æ ¹æ®æœ€å€¼å°†tpèµ‹å€¼   Assign 'TP' according to the maximum value
        # æ­¤å¤„åŸºäºŽä¸€ä¸ªé‡è¦ç†è®ºï¼šå¯¹äºŽä¸€ä¸ªé¢„æµ‹çš„æ™¶ç²’ï¼ŒçœŸå®žçš„æ™¶ç²’æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªæ™¶ç²’ä¸Žå…¶iou>0.5   Based on an important assumption: for a predicted grain, there is exactly one true grain with which its IOU is greater than 0.5.
        tp[thresholds < max_iou] = tp[thresholds < max_iou] + 1
    fp = num_pred - tp 
    fn = num_mask - tp
    map_score = np.average(tp/(tp + fp + fn))
    return map_score


def cluster_metrics(pred: np.ndarray, mask: np.ndarray, bg_value = 1) -> Tuple:
    """
    :param pred: prediction
    :param mask: ground truth
    :param bg_value: background value used for label function
    :return: RI, adjust_RI, VI, merger_error, split_error
    """

    RI = 0
    ad_RI = 0
    merger_error = 0
    split_error = 0
    VI = 0
    if np.amax(mask) == 255:
        pred = pred / 255
        mask = mask / 255
    
    label_pred, _ = label(pred, connectivity=1, background=bg_value, return_num=True)
    label_mask, _ = label(mask, connectivity=1, background=bg_value, return_num=True)

    # false merges(ç¼ºå¤± ), false splitsï¼ˆåˆ’ç—•ï¼‰
    merger_error, split_error = metrics.variation_of_information(label_pred, label_mask)
    VI = merger_error + split_error
    RI = rand_score(label_pred, label_mask)
    adjust_RI = adjusted_rand_score(label_pred, label_mask)
    return RI, adjust_RI, VI, merger_error, split_error


def ari(in_pred: np.ndarray, in_mask: np.ndarray, bg_value = 1) -> float:
    pred = in_pred.copy()
    mask = in_mask.copy()
    if np.amax(mask) == 255:
        pred = pred / 255
        mask = mask / 255
    
    label_pred, _ = label(pred, connectivity=1, background=bg_value, return_num=True)
    label_mask, _ = label(mask, connectivity=1, background=bg_value, return_num=True)    
    adjust_RI = ev.adj_rand_index(label_pred, label_mask)
    return adjust_RI


def vi(in_pred: np.ndarray, in_mask: np.ndarray, bg_value = 0) -> Tuple:

    vi, merger_error, split_error = 0.0, 0.0, 0.0
    pred = in_pred.copy()
    mask = in_mask.copy()
    if np.amax(mask) == 255:
        pred = pred / 255
        mask = mask / 255
    
    label_pred, _ = label(pred, connectivity=1, background=bg_value, return_num=True)
    label_mask, _ = label(mask, connectivity=1, background=bg_value, return_num=True)

    ## gala
    merger_error, split_error = ev.split_vi(label_pred, label_mask)
    vi = merger_error + split_error
    if math.isnan(vi):
        return 10, 5, 5
    return vi, merger_error, split_error


def cd(in_pred: np.ndarray, in_mask: np.ndarray, return_absolute = True, bg_value = 0) -> int:
    """
    cardinality difference
    
    R =|Gâˆ’S| where G is the number of distinct segments in the groundtruth, 
    and S is the number of distinct segments in the Prediction
    
    referenced from:
    Waggoner J, Zhou Y, Simmons J, et al. 3D materials image segmentation by 2D propagation: A graph-cut approach considering homomorphism[J]. IEEE transactions on image processing, 2013, 22(12): 5282-5293.
    """
    pred = in_pred.copy()
    mask = in_mask.copy()
    if np.amax(mask) == 255:
        pred = pred / 255
        mask = mask / 255
    
    _, num_pred = label(pred, connectivity=1, background=bg_value, return_num=True)
    _, num_mask = label(mask, connectivity=1, background=bg_value, return_num=True)
    
    cd_value = num_mask - num_pred
    if return_absolute:
        cd_value = abs(cd_value)
    return cd_value


# Post processing
def prun(image, kernel_size):
    """
    Remove small forks
    """
    label_map, num_label = label(image, connectivity=1, background=1, return_num=True)
    result = np.zeros(label_map.shape)
    for i in range(1, num_label + 1):
        tmp = np.zeros(label_map.shape)
        tmp[label_map == i] = 1
        D_kernel = np.ones((kernel_size, kernel_size), np.uint8)
        dil = cv2.dilate(tmp, D_kernel)
        dst = cv2.erode(dil, D_kernel)
        result[dst == 1] = 255
    result = 255 - result
    result[result == 255] = 1
    result = np.uint8(result)
    return result


def post_process_label(in_img: np.ndarray, prun=False) -> np.ndarray:
    out_img = morphology.skeletonize(in_img, method="lee")
    out_img = morphology.dilation(out_img, morphology.square(3))
    if prun:
        out_img = prun(out_img, 4)  # 5
    return out_img


def post_process_output(in_img: np.ndarray, prun=False) -> np.ndarray:
    out_img = morphology.dilation(in_img, morphology.square(2))  # 2  3
    out_img = morphology.skeletonize(out_img, method="lee")
    out_img = morphology.dilation(out_img, morphology.square(5))  # 5  3
    if prun:
        out_img = prun(out_img, 4)  # 5
    return out_img